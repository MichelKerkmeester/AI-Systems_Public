# Prompt - Evaluation & Refinement - v0.602

Systematic quality assessment and improvement for optimizing prompts through CLEAR evaluation as primary method, RCAF framework preference, ATLAS-powered refinement, and multi-format support.

## üìã Table of Contents

1. [‚úÖ CLEAR EVALUATION SYSTEM (PRIMARY)](#-clear-evaluation-system-primary)
2. [‚ö° QUICK EVAL WITH CLEAR](#-quick-eval-with-clear)
3. [üìä FULL EVALUATION PROCESS](#-full-evaluation-process)
4. [üéØ RCAF VS CRAFT EVALUATION](#-rcaf-vs-craft-evaluation)
5. [üîÑ FORMAT EVALUATION](#-format-evaluation)
6. [üß† ATLAS-POWERED REFINEMENT](#-atlas-powered-refinement)
7. [üîÑ PATTERN-BASED REFINEMENT](#-pattern-based-refinement)
8. [üöÄ CHALLENGE-BASED REFINEMENT](#-challenge-based-refinement)
9. [üìù REFINEMENT PATTERNS](#-refinement-patterns)
10. [üí° EXAMPLES](#-examples)
11. [üìà PERFORMANCE METRICS](#-performance-metrics)
12. [üéì KEY PRINCIPLES](#-key-principles)

---

## 1. ‚úÖ CLEAR EVALUATION SYSTEM (PRIMARY)

### The CLEAR Framework

**Correctness, Logic/Coverage, Expression, Arrangement, Reuse**

CLEAR is the primary evaluation method for all prompt assessments. Each dimension is scored 1-10, with a total possible score of 50.

### Detailed Scoring Rubric

#### Correctness (C) - Accuracy & Requirements
| Score | Description | Indicators |
|-------|-------------|------------|
| 9-10 | Perfect accuracy | All facts correct, requirements captured, no ambiguity |
| 7-8 | Mostly accurate | Minor clarifications needed, 90% correct |
| 5-6 | Adequate accuracy | Some errors, needs verification |
| 3-4 | Poor accuracy | Multiple errors, missing requirements |
| 1-2 | Incorrect | Fundamental misunderstandings |

#### Logic/Coverage (L) - Completeness & Flow
| Score | Description | Indicators |
|-------|-------------|------------|
| 9-10 | Complete coverage | All requirements addressed, perfect flow |
| 7-8 | Good coverage | Minor gaps, logical progression |
| 5-6 | Adequate coverage | Some gaps, logic mostly clear |
| 3-4 | Poor coverage | Major gaps, logic issues |
| 1-2 | Incomplete | Critical omissions |

#### Expression (E) - Clarity & Conciseness
| Score | Description | Indicators |
|-------|-------------|------------|
| 9-10 | Crystal clear | Perfect clarity, optimally concise |
| 7-8 | Clear | Minor ambiguities, well-expressed |
| 5-6 | Understandable | Some confusion, wordy |
| 3-4 | Unclear | Ambiguous, verbose |
| 1-2 | Confusing | Cannot understand intent |

#### Arrangement (A) - Structure & Organization
| Score | Description | Indicators |
|-------|-------------|------------|
| 9-10 | Perfect structure | Optimal organization, clear hierarchy |
| 7-8 | Good structure | Well-organized, minor improvements |
| 5-6 | Adequate structure | Basic organization present |
| 3-4 | Poor structure | Disorganized, hard to follow |
| 1-2 | No structure | Random, chaotic |

#### Reuse (R) - Adaptability & Templates
| Score | Description | Indicators |
|-------|-------------|------------|
| 9-10 | Highly reusable | Perfect template, easily adapted |
| 7-8 | Good reusability | Minor modifications needed |
| 5-6 | Some reusability | Moderate changes required |
| 3-4 | Limited reuse | Major rework needed |
| 1-2 | Single-use only | Not adaptable |

### CLEAR Grade Scale

| Total Score | Grade | Interpretation | Action Required |
|-------------|-------|----------------|-----------------|
| 45-50 | A+ | Exceptional | Ship immediately |
| 40-44 | A | Excellent | Minor polish only |
| 35-39 | B | Good | Target weak areas |
| 30-34 | C | Adequate | Consider framework switch |
| 25-29 | D | Poor | Major refinement needed |
| <25 | F | Failing | Complete rewrite with RCAF |

---

## 2. ‚ö° QUICK EVAL WITH CLEAR

### Rapid CLEAR Assessment (30 seconds)

```python
def quick_clear_eval(prompt):
    """Quick CLEAR scoring for rapid assessment"""
    
    scores = {
        'correctness': score_requirements_captured(prompt),  # 1-10
        'logic': score_completeness(prompt),                # 1-10
        'expression': score_clarity(prompt),                # 1-10
        'arrangement': score_structure(prompt),             # 1-10
        'reuse': score_adaptability(prompt)                # 1-10
    }
    
    total = sum(scores.values())
    weakest = min(scores, key=scores.get)
    
    return {
        'total': total,
        'grade': get_grade(total),
        'scores': scores,
        'priority_fix': weakest,
        'framework_rec': 'RCAF' if total < 35 else 'Current'
    }
```

### Quick CLEAR Report Template

```markdown
**QUICK CLEAR EVALUATION: [X]/50 (Grade: [A-F])**

üìä **Scores:**
‚Ä¢ Correctness: [X]/10
‚Ä¢ Logic/Coverage: [X]/10  
‚Ä¢ Expression: [X]/10
‚Ä¢ Arrangement: [X]/10
‚Ä¢ Reuse: [X]/10

**Strengths:** [Two highest dimensions]
**Priority Fix:** [Lowest dimension] ‚Üí [Solution]
**Framework:** [RCAF recommended if < 35]
**Quick Win:** [One immediate improvement]

Pattern: [User typically scores X in this dimension]
```

### Quick Fix Matrix by CLEAR Dimension

| Weak Dimension | Quick Fix | Framework Switch | Expected Gain |
|----------------|-----------|------------------|---------------|
| Correctness | Add verification steps | Consider CRAFT | +2-3 points |
| Logic/Coverage | Fill requirement gaps | Consider CRAFT | +2-3 points |
| Expression | Simplify with RCAF | Switch to RCAF | +3-4 points |
| Arrangement | Apply RCAF structure | Switch to RCAF | +2-3 points |
| Reuse | Parameterize elements | Either framework | +2-3 points |

---

## 3. üìä FULL EVALUATION PROCESS

### Comprehensive CLEAR Evaluation (2-3 minutes)

#### Step 1: Baseline CLEAR Scoring
```markdown
**BASELINE CLEAR SCORES:**
‚Ä¢ C (Correctness): [X]/10 - [specific issues]
‚Ä¢ L (Logic/Coverage): [X]/10 - [gaps identified]
‚Ä¢ E (Expression): [X]/10 - [clarity problems]
‚Ä¢ A (Arrangement): [X]/10 - [structure issues]
‚Ä¢ R (Reuse): [X]/10 - [adaptability limits]

**Total: [X]/50 - Grade: [A-F]**
```

#### Step 2: Framework Assessment
```markdown
**FRAMEWORK ANALYSIS:**
Current: [None/RCAF/CRAFT/Other]
Elements: [Count and list]

RCAF Suitability: [X]/10
- Would 4 elements suffice? [Yes/No]
- Clarity gain potential: [+X points]

CRAFT Necessity: [X]/10
- Requires 5+ elements? [Yes/No]
- Coverage gain potential: [+X points]

**Recommendation:** [RCAF/CRAFT] for [+X CLEAR points]
```

#### Step 3: Enhancement Projection
```markdown
**PROJECTED IMPROVEMENTS:**

With RCAF:
‚Ä¢ C: [Current] ‚Üí [Projected] (+X)
‚Ä¢ L: [Current] ‚Üí [Projected] (+X)
‚Ä¢ E: [Current] ‚Üí [Projected] (+X)
‚Ä¢ A: [Current] ‚Üí [Projected] (+X)
‚Ä¢ R: [Current] ‚Üí [Projected] (+X)
Total: [Current] ‚Üí [Projected] (+X)

With CRAFT (if applicable):
‚Ä¢ [Similar projection]

**Best Path:** [RCAF/CRAFT] for [total gain]
```

### Full Evaluation Report Template

```markdown
**COMPREHENSIVE CLEAR EVALUATION**

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
**Current State: [X]/50 (Grade: [A-F])**

Detailed Scores:
‚Ä¢ Correctness: [X]/10
  - [Specific strength/weakness]
‚Ä¢ Logic/Coverage: [X]/10
  - [Specific strength/weakness]
‚Ä¢ Expression: [X]/10
  - [Specific strength/weakness]
‚Ä¢ Arrangement: [X]/10
  - [Specific strength/weakness]
‚Ä¢ Reuse: [X]/10
  - [Specific strength/weakness]

**Framework Assessment:**
Current: [Framework]
Optimal: [RCAF/CRAFT]
Switch Benefit: +[X] points

**Priority Improvements:**
1. [Lowest dimension]: [Specific fix] (+X points)
2. [Second lowest]: [Specific fix] (+X points)
3. [Third area]: [Specific fix] (+X points)

**Recommended Action:**
[Apply RCAF / Enhance with CRAFT / Maintain current]

**Expected Outcome: [X]/50 ‚Üí [Y]/50**
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
```

---

## 4. üéØ RCAF VS CRAFT EVALUATION

### Framework Comparison Scoring

| Aspect | RCAF Impact | CRAFT Impact | Decision Factor |
|--------|-------------|--------------|-----------------|
| **Correctness** | +0 to +1 | +1 to +2 | Detail needs |
| **Logic/Coverage** | -1 to 0 | +1 to +2 | Completeness needs |
| **Expression** | +2 to +3 | -1 to 0 | Clarity priority |
| **Arrangement** | +1 to +2 | 0 to +1 | Simplicity helps |
| **Reuse** | +1 to +2 | 0 to +1 | Cleaner templates |

### Framework Selection Based on CLEAR

```python
def select_framework_by_clear(current_scores):
    """Choose framework based on CLEAR weaknesses"""
    
    if current_scores['expression'] < 7:
        return 'RCAF', 'Low expression score needs simplicity'
    
    elif current_scores['logic'] < 7:
        return 'CRAFT', 'Low coverage needs comprehensiveness'
    
    elif current_scores['total'] < 35:
        return 'RCAF', 'Low overall score needs clarity focus'
    
    elif current_scores['total'] > 42:
        return 'Current', 'High score, maintain approach'
    
    else:
        return 'User choice', 'Both frameworks viable'
```

### RCAF vs CRAFT Decision Matrix

| Current CLEAR | Best Framework | Rationale | Expected Gain |
|---------------|---------------|-----------|---------------|
| < 30/50 | RCAF | Need clarity foundation | +8-12 points |
| 30-35/50 | RCAF | Simplification priority | +5-8 points |
| 35-40/50 | User choice | Both viable | +3-5 points |
| 40-45/50 | Current | Working well | +2-3 points |
| > 45/50 | Current | Excellent already | +0-2 points |

---

## 5. üîÑ FORMAT EVALUATION

### Format Impact on CLEAR Scores

| Format | Correctness | Logic | Expression | Arrangement | Reuse | Typical Total |
|--------|-------------|-------|------------|-------------|-------|---------------|
| **Standard** | 0 | 0 | +1 | 0 | 0 | Baseline |
| **JSON** | +1 | +1 | -1 | +1 | +1 | +3 net |
| **SMILE** | +1 | +2 | -2 | +1 | 0 | +2 net |

### Format Selection for CLEAR Optimization

```markdown
**FORMAT EVALUATION:**

Current Format: [Standard/JSON/SMILE/None]
Current CLEAR: [X]/50

Format Projections:
‚Ä¢ Standard: [Best for Expression]
  - Projected CLEAR: [X]/50
  - Token impact: Baseline
  
‚Ä¢ JSON: [Best for Structure]
  - Projected CLEAR: [X]/50
  - Token impact: +5-10%
  
‚Ä¢ SMILE: [Best for Complex Logic]
  - Projected CLEAR: [X]/50
  - Token impact: +20-30%

**Recommendation:** [Format] for [reason]
```

**For detailed format specifications ‚Üí Prompt - JSON & SMILE Format Guide.md**

---

## 6. üß† ATLAS-POWERED REFINEMENT

### ATLAS Refinement with CLEAR Focus

#### A1 - Assess with CLEAR
- Complete CLEAR scoring (all 5 dimensions)
- Identify lowest 2 dimensions
- Measure complexity (1-10 scale)
- Evaluate framework fit
- Auto-challenge if complexity > 3

#### T - Transform for CLEAR Improvement
- Create minimal version (RCAF, target Expression)
- Create balanced version (RCAF+, target Balance)
- Create comprehensive version (CRAFT, target Coverage)
- Project CLEAR scores for each

#### L - Layer for Weak Dimensions
- Add elements targeting lowest CLEAR scores
- Apply RCAF for Expression issues
- Apply CRAFT for Coverage issues
- Filter to only score-improving layers

#### A2 - Assess CLEAR Changes
- Re-score all dimensions
- Verify improvements in weak areas
- Check for unintended score drops
- Calculate net CLEAR gain

#### S - Synthesize with Scores
- Choose version with highest CLEAR
- Document score improvements
- Present with before/after CLEAR
- Record pattern for learning

### CLEAR-Driven Refinement Process

```python
def refine_with_clear_focus(prompt, clear_scores):
    """Refinement targeting CLEAR improvements"""
    
    weak_dimensions = get_lowest_two(clear_scores)
    
    refinements = {
        'correctness': add_requirements_verification,
        'logic': fill_coverage_gaps,
        'expression': apply_rcaf_simplification,
        'arrangement': restructure_with_rcaf,
        'reuse': extract_template_parameters
    }
    
    for dimension in weak_dimensions:
        prompt = refinements[dimension](prompt)
        
    new_scores = evaluate_clear(prompt)
    improvement = new_scores['total'] - clear_scores['total']
    
    return prompt, new_scores, improvement
```

---

## 7. üîÑ PATTERN-BASED REFINEMENT

### Pattern Recognition with CLEAR History

| Pattern Type | Recognition Signal | Typical CLEAR | Action |
|--------------|-------------------|---------------|--------|
| **Always Low Expression** | E < 7 consistently | Focus on clarity | Default to RCAF |
| **Coverage Issues** | L < 7 repeatedly | Completeness gaps | Consider CRAFT |
| **Structure Problems** | A < 7 pattern | Organization issues | Apply RCAF structure |
| **High Performers** | Consistent 40+ | Working approach | Minimal changes |

### CLEAR Pattern Learning

```python
def learn_clear_patterns(history):
    """Track CLEAR scoring patterns"""
    
    patterns = {
        'weak_dimensions': find_consistent_lows(history),
        'strong_dimensions': find_consistent_highs(history),
        'improvement_rates': calculate_gains(history),
        'framework_success': {
            'rcaf_avg_clear': avg_clear_with_rcaf(history),
            'craft_avg_clear': avg_clear_with_craft(history)
        }
    }
    
    return patterns
```

### Pattern-Based Enhancement Strategy

| User Pattern | Strategy | Framework | Target CLEAR |
|--------------|----------|-----------|--------------|
| Expression struggles | Simplify aggressively | RCAF | E: 9+/10 |
| Coverage perfectionist | Comprehensive approach | CRAFT | L: 9+/10 |
| Structure lover | Clear organization | RCAF | A: 9+/10 |
| Efficiency focused | Balanced approach | RCAF | 43+/50 |

---

## 8. üöÄ CHALLENGE-BASED REFINEMENT

### Challenge Triggers by CLEAR Score

| CLEAR Score | Challenge Level | Action | Framework Push |
|-------------|----------------|--------|----------------|
| **45-50** | None | Polish only | Maintain |
| **40-44** | Gentle | Suggest refinements | Consider RCAF |
| **35-39** | Moderate | Recommend changes | Suggest RCAF |
| **30-34** | Strong | Push for overhaul | Switch to RCAF |
| **<30** | Aggressive | Complete rewrite | Force RCAF |

### CLEAR-Based Challenge Templates

**High Score (40+):**
```
Current CLEAR: [X]/50 - Already excellent!

Minor enhancement possible:
- [Lowest dimension]: Could improve from [X] to [Y]

Worth the effort?
```

**Medium Score (30-39):**
```
Current CLEAR: [X]/50 - Good, but could be better

Simplifying with RCAF could achieve:
- Expression: [Current] ‚Üí [+3]
- Arrangement: [Current] ‚Üí [+2]
- Total: [Current] ‚Üí [Projected]

Switch to RCAF?
```

**Low Score (<30):**
```
Current CLEAR: [X]/50 - Significant improvement needed

RCAF restructuring recommended:
- Will improve Expression by +[X]
- Will improve Arrangement by +[X]
- Target: 40+/50

Proceed with RCAF rewrite?
```

---

## 9. üìù REFINEMENT PATTERNS

### Common CLEAR Improvements

| Issue | CLEAR Impact | RCAF Fix | Score Gain |
|-------|--------------|----------|------------|
| **Vague requirements** | C:4, L:5 | Add specific Context/Action | +4-5 points |
| **No role defined** | C:6, E:6 | Add clear Role | +2-3 points |
| **Poor structure** | A:4, E:5 | Apply RCAF format | +4-5 points |
| **Over-complex** | E:4, A:5 | Simplify to RCAF | +5-6 points |
| **Not reusable** | R:3 | Extract parameters | +3-4 points |

### RCAF Transformation Examples with CLEAR

**Before - Vague (CLEAR: 22/50):**
```
"Analyze our sales data and provide insights"

C:4 L:3 E:5 A:5 R:5 = 22/50
```

**After - RCAF (CLEAR: 45/50):**
```
Role: Senior data analyst specializing in SaaS metrics.
Context: Q4 2024 sales data from our B2B platform (50K transactions).
Action: Identify top 3 revenue drivers and create predictive model for Q1 2025.
Format: Executive dashboard with bullet insights and supporting charts.

C:9 L:8 E:10 A:9 R:9 = 45/50
```

**Improvement: +23 points (104% gain)**

---

## 10. üí° EXAMPLES

### Example 1: Progressive CLEAR Improvement

**Initial Assessment:**
```
"Write a technical guide about machine learning"
CLEAR: C:3 L:4 E:5 A:4 R:4 = 20/50 (Grade: F)
```

**Round 1 - Add RCAF (Target: Expression):**
```
Role: ML educator with 10 years teaching experience.
Context: Writing for developers new to machine learning.
Action: Create comprehensive guide covering supervised/unsupervised learning.
Format: 2000-word tutorial with code examples and diagrams.

CLEAR: C:7 L:7 E:8 A:8 R:7 = 37/50 (Grade: B)
```

**Round 2 - Enhance Specificity (Target: Correctness):**
```
Role: ML educator specializing in practical applications.
Context: Python developers (3+ years) entering ML field, familiar with numpy/pandas.
Action: Create beginner's guide covering:
- Supervised learning (regression, classification)
- Unsupervised learning (clustering, dimensionality reduction)
- Model evaluation techniques
- One practical project
Format: 2000-word tutorial with 5 Python code examples, 3 visualizations, and resources list.

CLEAR: C:9 L:9 E:9 A:9 R:8 = 44/50 (Grade: A)
```

### Example 2: Framework Comparison with CLEAR

**Same Task - Two Frameworks:**

**RCAF Version (CLEAR: 43/50):**
```
Role: Customer success analyst with churn prediction expertise.
Context: 12 months subscription data, 10K B2B customers, 15% churn rate.
Action: Build churn prediction model and identify top 3 risk factors.
Format: Jupyter notebook with model code and executive summary.

C:8 L:8 E:10 A:9 R:8 = 43/50
```

**CRAFT Version (CLEAR: 41/50):**
```
Context: Analyzing customer churn for B2B SaaS platform with 10K customers,
12 months historical data, 15% annual churn rate, need for actionable insights.
Role: Data scientist specializing in customer analytics and predictive modeling.
Action: Develop comprehensive churn analysis including data exploration,
feature engineering, model building, validation, and interpretation.
Format: Complete Jupyter notebook with code, visualizations, and findings.
Target: 85% model accuracy, identify top risk factors, reduce churn by 20%.

C:9 L:9 E:7 A:8 R:8 = 41/50
```

**Analysis:** RCAF scores higher due to superior Expression (+3) despite lower Coverage (-1)

---

## 11. üìà PERFORMANCE METRICS

### CLEAR-Based KPIs

**Quality Targets:**
- Average CLEAR score: > 42/50
- Grade distribution: 60% A, 30% B, 10% C
- Expression average: > 8.5/10
- Correctness average: > 8.5/10
- No scores below 25/50

**Improvement Metrics:**
- Average gain per refinement: +8 points
- First-pass success (35+): > 70%
- Framework switch success: +5 points minimum
- Weak dimension improvement: +2 minimum

### CLEAR Tracking Dashboard

```markdown
**CLEAR PERFORMANCE DASHBOARD**

üìä **Session Statistics:**
- Evaluations completed: [X]
- Average CLEAR: [X]/50
- Average improvement: +[X] points

üìà **Dimension Averages:**
- Correctness: [X]/10
- Logic/Coverage: [X]/10
- Expression: [X]/10 ‚≠ê [if highest]
- Arrangement: [X]/10
- Reuse: [X]/10

üéØ **Framework Performance:**
- RCAF average: [X]/50
- CRAFT average: [X]/50
- RCAF adoption: [X]%

‚úÖ **Success Metrics:**
- A grades: [X]%
- B grades: [X]%
- Improvement rate: [X]%
```

---

## 12. üéì KEY PRINCIPLES

### Evaluation Philosophy

> "CLEAR scores tell the truth. Expression beats Coverage. RCAF delivers clarity."

### Core Evaluation Principles

| Principle | Description | CLEAR Focus | Priority |
|-----------|-------------|-------------|----------|
| **Measure First** | Always score before changing | All dimensions | 1.0 |
| **Expression Priority** | Clarity trumps completeness | E > L | 0.9 |
| **Framework Fit** | RCAF default, CRAFT when needed | E vs L balance | 0.8 |
| **Target Weakness** | Fix lowest scores first | Lowest 2 dims | 0.8 |
| **Verify Gains** | Confirm improvements | Re-score always | 0.7 |

### CLEAR Interpretation Guidelines

1. **Below 30/50:** Complete rewrite with RCAF needed
2. **30-35/50:** Major refinement, consider RCAF
3. **35-40/50:** Good foundation, target weak dimensions
4. **40-45/50:** Excellent, minor polish only
5. **45-50/50:** Exceptional, ship immediately

### Success Criteria

**Excellent Evaluation Achieves:**
- ‚úÖ Complete CLEAR scoring (all 5 dimensions)
- ‚úÖ Framework recommendation based on scores
- ‚úÖ Clear improvement path identified
- ‚úÖ Projected gains calculated
- ‚úÖ Pattern learning applied
- ‚úÖ Format optimization considered
- ‚úÖ Minimum 35/50 achieved

### The CLEAR Mantra

```
Correctness ensures accuracy
Logic provides coverage
Expression delivers clarity
Arrangement creates structure
Reuse enables scalability

Together: CLEAR excellence
```

---

*Excellence through CLEAR measurement and RCAF simplicity. Every evaluation drives improvement. Every score tells a story. Every refinement targets specific weaknesses. Expression beats Coverage. Simplicity beats Complexity. CLEAR scores never lie. For format specifications, see Prompt - JSON & SMILE Format Guide.md*