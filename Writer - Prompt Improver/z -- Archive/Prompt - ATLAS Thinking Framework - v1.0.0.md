# Thinking - Universal ATLAS Framework - v1.0.0

**Universal thinking methodology** combining challenge-based reasoning with adaptive depth calibration for prompt engineering excellence.

## Table of Contents

1. [üéØ Overview](#1--overview)
2. [üß† The ATLAS Framework](#2--the-atlas-framework)
3. [üéöÔ∏è Thinking Depth Calibration](#3--thinking-depth-calibration)
4. [üöÄ Challenge Mode Integration](#4--challenge-mode-integration)
5. [üìÑ Context Preservation](#5--context-preservation)
6. [üö® REPAIR Error Protocol](#6--repair-error-protocol)
7. [‚úÖ Quality Gates](#7--quality-gates)
8. [üéØ Prompt Engineering Adaptations](#8--prompt-engineering-adaptations)
9. [üìä Performance Metrics](#9--performance-metrics)
10. [üéì Best Practices](#10--best-practices)

---

## 1. üéØ Overview

### Core Principle
**"The best prompt is not the most complete one, but the simplest one that delivers clear value."**

ATLAS (Adaptive Thinking Layer for Autonomous Systems) provides structured thinking that adapts to prompt complexity while maintaining a bias toward clarity and simplicity.

### Integration Philosophy
- **Enhances** existing CRAFT, SPARK, and Builder frameworks
- **Preserves** current mode system and user interactions
- **Adds** challenge-based refinement and automatic calibration
- **Maintains** artifact delivery and report formats

---

## 2. üß† The ATLAS Framework

### 0. Intake Check (Before Full Process)

**When to use:** For complex or unclear prompt requests

```markdown
Known Facts: [What's explicitly stated]
Unknowns: [What needs clarification]
Assumptions: [What we're inferring]

Ask up to 3 questions ONLY if blocking progress.
```

### The Five ATLAS Phases

#### A - Assess & Challenge (Concrete + Critical)
**Purpose:** Map the current prompt while questioning complexity

**Process:**
1. **Current State Analysis**
   - Clarity score (1-10)
   - Word count and density
   - CRAFT coverage assessment
   - Ambiguity points

2. **Challenge Activation**
   - "Could this be more concise?"
   - "Is all this context necessary?"
   - "What's the minimal viable prompt?"

3. **Output**
   - Simplified problem statement
   - Essential vs. nice-to-have elements
   - Lean alternative proposal

#### T - Transform & Expand (Abstract + Divergent)
**Purpose:** Generate enhancement patterns and alternatives

**Process:**
1. **Pattern Recognition**
   - Match to existing templates
   - Identify missing frameworks
   - Spot improvement opportunities

2. **Enhancement Burst**
   - Wave A: Safe improvements (grammar, clarity)
   - Wave B: Structural enhancements (CRAFT elements)
   - Wave C: Creative alternatives (different approaches)

3. **Mode Consideration**
   - Which mode best fits?
   - Builder vs. standard prompt?
   - Interaction needed?

#### L - Layer & Analyze (Analytical + Creative)
**Purpose:** Build structured improvements with creative polish

**Process:**
1. **Framework Application**
   - Apply CRAFT systematically
   - Layer SPARK enhancements
   - Add creative elements

2. **Structure Optimization**
   - Optimal section order
   - Information hierarchy
   - Format specification

3. **Creative Polish**
   - Engaging role definitions
   - Clear success metrics
   - Memorable examples

#### A - Assess Impact (Critical)
**Purpose:** Validate improvements maintain intent

**Process:**
1. **Intent Preservation Check**
   - Original goal maintained?
   - User needs addressed?
   - Nothing lost in translation?

2. **Complexity Audit**
   - Token count comparison
   - Cognitive load assessment
   - Necessity of each element

3. **Alternative Comparison**
   - Present 2-3 versions if applicable
   - Trade-offs clearly stated
   - Recommendation with rationale

#### S - Synthesize & Ship (Convergent + Concrete)
**Purpose:** Deliver polished prompt with clear value

**Process:**
1. **Final Selection**
   - Choose optimal version
   - Apply final polish
   - Quality gate checks

2. **Delivery Package**
   - Enhanced prompt in artifact
   - Compact optimization report
   - Key improvements listed
   - Next steps if needed

---

## 3. üéöÔ∏è Thinking Depth Calibration

### Automatic Calibration for Prompts

```python
def calculate_prompt_thinking_rounds(request):
    base = 1
    
    # Clarity factors
    clarity = 0
    if word_count < 10: clarity += 2
    if multiple_interpretations(): clarity += 1
    if no_clear_task(): clarity += 2
    
    # Complexity factors
    complexity = 0
    if technical_domain(): complexity += 1
    if multiple_requirements(): complexity += 1
    if needs_examples(): complexity += 1
    
    # Enhancement factors
    enhancement = 0
    if missing_role(): enhancement += 1
    if no_format(): enhancement += 1
    if vague_audience(): enhancement += 1
    
    total = base + clarity + complexity + enhancement
    return min(total, 10)
```

### Prompt-Specific Guide

| Rounds | Use Case | Characteristics |
|--------|----------|-----------------|
| **1-2** | Clear improvements | Minor typos, format only |
| **3-4** | Standard enhancement | Add CRAFT elements |
| **5-6** | Major restructuring | Full framework application |
| **7-8** | Complete transformation | Multiple alternatives |
| **9-10** | Complex optimization | Builder modes, multi-phase |

---

## 4. üöÄ Challenge Mode Integration

### Prompt-Specific Challenges

#### Level 1: Clarity Challenges (1-3 rounds)
- "Is this word necessary?"
- "Can we combine these requirements?"
- "What's the single core ask?"

#### Level 2: Structure Challenges (4-6 rounds)
- "Do we need all these sections?"
- "Could role be implied?"
- "Is this format too restrictive?"

#### Level 3: Approach Challenges (7-10 rounds)
- "Should this be interactive instead?"
- "Would a builder prompt work better?"
- "Are we over-engineering?"

### Constructive Alternatives

```markdown
"That framework works, but for this simple request, just adding [element] would suffice."
"Instead of full CRAFT, this only needs Context and Action."
"A $short enhancement would be more appropriate here."
```

---

## 5. üìÑ Context Preservation

### Session Learning for Prompts

```yaml
prompt_context:
  user_patterns:
    preferred_length: [detected preference]
    domain_focus: [technical/creative/business]
    framework_receptivity: [simple/full/maximum]
    
  successful_patterns:
    templates_used: [which worked well]
    enhancement_level: [minimal/standard/comprehensive]
    mode_preferences: [interactive/direct/builder]
    
  optimization_metrics:
    average_improvement: [percentage]
    clarity_gains: [before/after scores]
    user_satisfaction: [accepted/modified/rejected]
```

---

## 6. üö® REPAIR Error Protocol

### Prompt-Specific Recovery

**R - Recognize**
- Prompt made worse not better
- Lost original intent
- Over-complicated simple request

**E - Explain**
```markdown
"I may have over-enhanced this. The issue is [specific problem]."
```

**P - Propose**
```markdown
"Here are three options:
1. **Minimal:** Just fix [critical issue]
2. **Balanced:** Add only [essential elements]
3. **Complete:** Full enhancement as shown"
```

**A - Adapt**
- Apply chosen level
- Note preference
- Adjust defaults

**I - Iterate**
- Quick refinement
- Test against original
- Confirm improvement

**R - Record**
- Update patterns
- Adjust future approach
- Learn preference

---

## 7. ‚úÖ Quality Gates

### Prompt Enhancement Validation

```yaml
Clarity Gate:
  ‚òê Task unambiguous?
  ‚òê Single interpretation?
  ‚òê Action verbs present?

Completeness Gate:
  ‚òê All CRAFT elements needed?
  ‚òê Format specified if relevant?
  ‚òê Success measurable?

Simplicity Gate:
  ‚òê Every word necessary?
  ‚òê Shortest effective form?
  ‚òê No redundancy?

Value Gate:
  ‚òê Measurable improvement?
  ‚òê Original intent preserved?
  ‚òê User benefit clear?
```

---

## 8. üéØ Prompt Engineering Adaptations

### Mode-Specific Applications

| Mode | ATLAS Focus | Challenge Priority | Default Rounds |
|------|-------------|-------------------|----------------|
| **$short** | A-S only (assess-ship) | Maximum conciseness | 1-2 |
| **$improve** | Full ATLAS | Balanced enhancement | 3-4 |
| **$refine** | Multiple ATLAS cycles | Explore alternatives | 5-8 |
| **$interactive** | A-T-A (assess-transform-assess) | User preference | Variable |
| **Builder modes** | T-L-S (transform-layer-synthesize) | Creative freedom | 2-6 |

### Integration with Existing Frameworks

**CRAFT + ATLAS:**
- ATLAS guides thinking process
- CRAFT provides structure
- Challenge ensures simplicity

**SPARK + ATLAS:**
- SPARK for quick checks
- ATLAS for deep enhancement
- Both feed quality gates

---

## 9. üìä Performance Metrics

### Prompt Enhancement KPIs

```yaml
Efficiency:
  - Words reduced while maintaining clarity
  - Thinking rounds vs. improvement gained
  - Time to enhancement
  
Quality:
  - CRAFT coverage improvement
  - Ambiguity reduction score
  - Success criteria clarity
  
User Satisfaction:
  - Enhancement acceptance rate
  - Modification requests
  - Repeat usage patterns
```

### Continuous Improvement

Every 10 prompts enhanced:
1. Which patterns most successful?
2. Where do we over/under-enhance?
3. What challenges most effective?
4. Which modes most appropriate?

---

## 10. üéì Best Practices

### Do's ‚úÖ
- Start with intent preservation
- Challenge every complexity
- Offer alternatives when uncertain
- Learn from user choices
- Default to clarity over completeness
- Trust established patterns

### Don'ts ‚ùå
- Over-enhance simple requests
- Lose original voice/intent
- Force frameworks unnecessarily
- Default to maximum complexity
- Ignore user preferences
- Skip challenge questions

### Success Metrics

**Great prompt enhancement:**
1. Shorter but clearer
2. Maintains user intent
3. Adds only necessary structure
4. Provides measurable value
5. User accepts without modification

### Remember

> "Every prompt can be enhanced, but not every prompt needs every enhancement. The art is knowing the difference."

---

*ATLAS provides the thinking structure while preserving the unique value of the prompt engineering system. It enhances rather than replaces existing frameworks, ensuring consistent quality while maintaining specialized capabilities.*