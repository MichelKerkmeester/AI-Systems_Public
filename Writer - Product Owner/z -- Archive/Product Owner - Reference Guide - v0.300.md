# Product Owner - Reference Guide - v0.300

Comprehensive reference for symbols, formats, templates, and quality standards with ATLAS Framework, Challenge Mode, and Pattern Learning integration.

## üìã Table of Contents

1. [üß† ATLAS FRAMEWORK REFERENCE](#1--atlas-framework-reference)
2. [üì§ SYMBOL DICTIONARY](#2--symbol-dictionary)
3. [üìã TICKET TEMPLATES WITH CHALLENGES](#3--ticket-templates-with-challenges)
4. [üìö DOCUMENTATION TEMPLATE](#4--documentation-template)
5. [üíª SPEC TEMPLATE](#5--spec-template)
6. [‚úçÔ∏è TEXT TEMPLATE](#6--text-template)
7. [üí° CHALLENGE MODE PATTERNS](#7--challenge-mode-patterns)
8. [üîÑ PATTERN LEARNING](#8--pattern-learning)
9. [‚úÖ QUALITY STANDARDS](#9--quality-standards)
10. [üìù FORMATTING RULES](#10--formatting-rules)
11. [üéØ COMPLEXITY DETECTION](#11--complexity-detection)
12. [üí° COMPLETE EXAMPLES](#12--complete-examples)
13. [üîß TROUBLESHOOTING WITH REPAIR](#13--troubleshooting-with-repair)

---

## 1. üß† ATLAS FRAMEWORK REFERENCE

### The Five Phases

| Phase | Full Name | Key Activities | When Active | Challenge Focus |
|-------|-----------|---------------|-------------|-----------------|
| **A** | Assess & Challenge | Map reality, question everything, identify simplifications | Always (1-10 rounds) | "Is this necessary?" |
| **T** | Transform & Expand | Generate solutions (safe‚Üíadjacent‚Üíwild), apply patterns | 3+ rounds | "What exists already?" |
| **L** | Layer & Analyze | Build MECE trees, find leverage points, creative leaps | 5+ rounds | "Where's the 80/20?" |
| **A** | Assess Impact | Red team, premortem, test assumptions | 7+ rounds | "How will this fail?" |
| **S** | Synthesize & Ship | Score options, decide, create execution plan | Always (1-10 rounds) | "Ship lean first?" |

### Thinking Round Calibration Formula

```python
def calculate_thinking_rounds(request, patterns=None):
    # Base calculation
    complexity = assess_complexity(request)  # 0-6 points
    uncertainty = assess_uncertainty(request)  # 0-4 points
    stakes = assess_stakes(request)  # 0-5 points
    
    total = 1 + complexity + uncertainty + stakes
    
    # Pattern adjustment (if session patterns exist)
    if patterns and patterns.consistent_preference:
        total = adjust_for_user_preference(total, patterns)
    
    return min(total, 10)
```

### Phase Activation by Rounds

```markdown
1-2 rounds:  A ‚Üí S (Quick assess and ship)
3-4 rounds:  A ‚Üí T ‚Üí S (Add exploration)
5-6 rounds:  A ‚Üí T ‚Üí L ‚Üí S (Add analysis)
7-8 rounds:  A ‚Üí T ‚Üí L ‚Üí A ‚Üí S (Full cycle)
9-10 rounds: Deep ATLAS with multiple iterations
```

### Intake Check (Optional Pre-Phase)
**When:** Complex/unclear requests (5+ rounds)
**Skip:** Simple edits, clear instructions

```markdown
Known Facts: [What we can verify]
Unknowns: [What we need to discover]  
Assumptions: [What we're assuming]

Ask up to 3 questions ONLY if blocking progress.
```

**Full framework details ‚Üí Product Owner - ATLAS Thinking Framework.md**

---

## 2. üì§ SYMBOL DICTIONARY

### Primary Symbols with Challenge Context

| Symbol | Usage | Context | Challenge Check | Pattern Note |
|--------|-------|---------|-----------------|--------------|
| **‚åò** | Section headers, "About" | All modes | Clear purpose? | User prefers minimal? |
| **‚óá** | Requirements header | Tickets only | All necessary? | Previous reductions? |
| **‚óªÔ∏è** | Feature sections | Documentation | Too detailed? | Typical depth? |
| **‚óä** | Sub-headings (bold) | All modes | Can combine? | Consolidation pattern? |
| **‚ó≥** | Designs & References | Tickets | Links ready? | Standard placeholders? |
| **‚Üí** | Key Problems/Reasons | Tickets | Real problems? | Format consistency |
| **‚ú¶** | Success criteria | Tickets | Measurable? | Achievability check |
| **‚úì** | Resolution checklist | Tickets | Too granular? | Typical count |
| **‚ãà** | Dependencies | Complex tickets | Real blockers? | Often challenged |
| **‚ö°** | Risks | Complex tickets | Mitigatable? | Risk tolerance |
| **üìö** | Resources | Documentation | Helpful? | Resource preference |
| **‚Äî** | Sub-categories | Under ‚óä only | Needed? | Usually simplified |

### Hierarchy Rules with Simplification Checks

```markdown
## üìã Table of Contents [MANDATORY - sections only, no subsections]
# ‚åò Top Level (About/Overview) [Clear intro?]
---
### ‚Üí Key problems: [NOT in TOC - Real problems or symptoms?]
- First problem (minimum 2)
- Second problem

### ‚Üí Reasons why: [NOT in TOC - Quantifiable value?]
- First value (minimum 2)
- Second value
---
## ‚ó≥ Designs & References [MANDATORY - Links or placeholders]
- [Figma designs - to be added]
- [API documentation - to be added]
---
## ‚óá Requirements (Tickets) [Each one necessary?]
**‚óä Sub-heading** [Can consolidate?]
‚Äî Sub-category [Really needed?]
- Detail item [Adds value?]
---
## ‚ú¶ Success Criteria [Measurable outcomes]
- Outcome 1
- Outcome 2
---
## ‚úì Resolution Checklist [MANDATORY warning above]

‚ö†Ô∏è Complete all Resolution Checklist items before moving to QA

[] First item [Too detailed?]
[] Second item [Necessary?]
---
## ‚ãà Dependencies [If applicable - True blockers?]
- External service
- Team coordination
```

**Complete symbol reference ‚Üí Product Owner - Reference Guide.md#symbol-dictionary**

---

## 3. üìã TICKET TEMPLATES WITH CHALLENGES

### Auto-Scaling Formula with Pattern Influence
```python
def detect_complexity(request, session_patterns=None):
    # Keyword detection
    if has_keywords(['bug', 'fix', 'update', 'typo']):
        complexity = 'simple'  # 2-3 sections, 4-6 resolution
    elif has_keywords(['feature', 'dashboard', 'workflow']):
        complexity = 'standard'  # 4-5 sections, 8-12 resolution
    elif has_keywords(['platform', 'architecture', 'migration']):
        complexity = 'complex'  # 6-8 sections, 12-20 resolution
    
    # Apply pattern influence if available
    if session_patterns and session_patterns.complexity_preference:
        complexity = adjust_for_pattern(complexity, session_patterns)
    
    return complexity
```

### Simple Ticket Template (2-3 sections, 4-6 resolution)
```markdown
[BE] Bug Fix: Login Token Expiration

## üìã Table of Contents
- [‚åò About](#-about)
- [‚ó≥ Designs & References](#-designs--references)
- [‚óá Requirements](#-requirements)
- [‚ú¶ Success Criteria](#-success-criteria)
- [‚úì Resolution Checklist](#-resolution-checklist)

# ‚åò About

Users cannot log in due to token validation error that started after the recent deployment, blocking all platform access.

[Challenge Point: Is this affecting all users or a subset?]
[Pattern: User typically prefers quick fixes over analysis]

---

### ‚Üí Key problems:
- Authentication tokens expiring after 5 minutes instead of 24 hours
- All users logged out unexpectedly, unable to re-authenticate

[Challenge addressed: Root cause identified in token service, not symptom]

### ‚Üí Reasons why:
- Critical blocker preventing all user access (100% impact)
- Revenue loss of $50K per hour based on average transaction volume

[Pattern: User prefers quantified impact statements]

---

## ‚ó≥ Designs & References
- [System architecture diagram - to be added]
- [Error logs dashboard - link pending]
- [Token service documentation - to be added]

---

## ‚óá Requirements

**‚óä Immediate Fix**
‚Äî Token Validation
- Identify misconfigured expiration setting
- Update to correct 24-hour duration
- Validate against staging environment
- Add monitoring for token lifespans

[Challenge accepted: Config change sufficient, no code needed]

---

## ‚ú¶ Success Criteria
- All users can authenticate successfully
- Tokens persist for full 24-hour duration
- Zero authentication errors in monitoring
- Response time remains under 200ms

---

## ‚úì Resolution Checklist

‚ö†Ô∏è Complete all Resolution Checklist items before moving to QA

[] Update token expiration config to 86400 seconds
[] Test with 5 different user types
[] Deploy to staging and verify
[] Monitor for 1 hour post-deployment
[] Update runbook with fix details
[] Create alert for token expiration anomalies

**Labels:** bug, critical, authentication, hotfix
**Thinking rounds used:** 2
**ATLAS phases:** A ‚Üí S
**Challenge decisions:** Config over code
**Pattern applied:** Quick fix preference
```

### Standard Ticket Template (4-5 sections, 8-12 resolution)
```markdown
[FS] User Analytics Dashboard

## üìã Table of Contents
- [‚åò About](#-about)
- [Challenge Summary](#challenge-summary)
- [‚ó≥ Designs & References](#-designs--references)
- [‚óá Requirements](#-requirements)
- [‚ú¶ Success Criteria](#-success-criteria)
- [‚úì Resolution Checklist](#-resolution-checklist)
- [‚ãà Dependencies](#-dependencies)

# ‚åò About

Real-time analytics dashboard enabling users to track their account activity, usage patterns, and performance metrics for data-driven decision making.

[Challenge addressed: Reduced from "complete analytics platform" to "essential metrics dashboard"]
[Pattern recognized: User prefers phased delivery based on 3 previous features]

---

## Challenge Summary

**Initial scope:** 10 widgets, 50+ metrics, custom everything
**Challenges applied:**
1. "Could we start with 3 core widgets?" ‚Üí Accepted
2. "Use existing charting library?" ‚Üí Accepted (Recharts)
3. "Ship MVP in 1 week?" ‚Üí Negotiated to 2 weeks

**Result:** 3-week phased delivery vs 8-week monolith
**Pattern:** Consistent with user's phasing preference

---

### ‚Üí Key problems:
- No visibility into usage patterns causing blind decision-making
- Manual data compilation taking 5+ hours weekly per team
- Missing competitive feature cited in 30% of churn surveys

[Challenge: Primary problem identified as visibility, others are symptoms]

### ‚Üí Reasons why:
- Reduce support tickets by 40% (200 tickets/month ‚Üí 120)
- Save $200K annually in manual reporting time
- Match competitor features to reduce churn by projected 15%

[Pattern: User prefers specific metrics over vague benefits]

---

## ‚ó≥ Designs & References
- [Figma mockups - dashboard layouts](https://figma.com/...)
- [Competitor analysis document](link)
- [User research findings - to be added]
- [Analytics API specification - pending]
- [Recharts documentation](https://recharts.org)

---

## ‚óá Requirements

### Phase 1: Core Dashboard (Week 1)

**‚óä Essential Widgets**
‚Äî Usage Metrics
- Daily active users graph
- Session duration histogram
- Top 10 features by usage

‚Äî Performance Panel
- API response times
- Error rate percentage
- System uptime display

**‚óä Basic Features**
‚Äî Data Management
- 7-day default view
- CSV export only
- Manual refresh button

[Challenge accepted: 3 widgets instead of 10]

---

### Phase 2: Enhanced Analytics (Week 2)

**‚óä Additional Widgets**
‚Äî Engagement Metrics
- User retention cohorts
- Feature adoption funnel
- Time-to-value tracking

**‚óä Advanced Features**
‚Äî Interactivity
- Customizable date ranges
- Real-time updates (WebSocket)
- Multiple export formats

[Pattern: Phased approach aligns with previous projects]

---

### Phase 3: Full Platform (Week 3)

**‚óä Power Features**
‚Äî Customization
- Drag-and-drop layout
- Custom metric builder
- Saved view templates

[Deferred from Phase 1 after challenge]

---

## ‚ú¶ Success Criteria
- Dashboard loads in under 2 seconds (current: N/A)
- Real-time updates within 5 seconds of event
- 90% user satisfaction in post-launch survey
- Mobile responsive down to 320px width
- Zero critical bugs in production

---

## ‚úì Resolution Checklist

‚ö†Ô∏è Complete all Resolution Checklist items before moving to QA

### Phase 1 (Week 1)
[] Design 3 core widget layouts
[] Implement usage metrics widget
[] Implement performance panel
[] Create basic dashboard container
[] Add CSV export functionality
[] Write unit tests (80% coverage)

### Phase 2 (Week 2)
[] Add engagement widgets
[] Implement WebSocket connection
[] Add date range selector
[] Create export service
[] Performance optimization
[] Integration testing

### Phase 3 (Week 3)
[] Build layout customization
[] Add metric builder UI
[] Implement view templates
[] Security audit
[] Load testing
[] Documentation

---

## ‚ãà Dependencies
- Analytics API v3.0 upgrade (in progress)
- Design system v2.0 components (ready)
- Data warehouse read access (pending approval)

[Challenge: Reduced from 8 dependencies through scope reduction]

**Labels:** feature, dashboard, analytics, phased
**Thinking rounds used:** 4
**ATLAS phases:** A ‚Üí T ‚Üí S
**Challenges accepted:** 3 of 4 proposed
**Pattern confidence:** High (similar to previous 3 features)
```

### Complex Ticket Template (6-8 sections, 12-20 resolution)
```markdown
[FS] Multi-tenant Payment Platform

## üìã Table of Contents
- [‚åò About](#-about)
- [Challenge Summary](#challenge-summary)
- [‚ó≥ Designs & References](#-designs--references)
- [‚óá Implementation Strategy](#-implementation-strategy)
- [‚ú¶ Success Criteria](#-success-criteria)
- [‚úì Resolution Checklist](#-resolution-checklist)
- [‚ãà Major Dependencies](#-major-dependencies)
- [‚ö° Risk Mitigation](#-risk-mitigation)

# ‚åò About

Enterprise payment processing system supporting multiple providers, currencies, and compliance requirements for global market expansion with focus on reliability and regulatory compliance.

[Major challenge: "Build everything custom" ‚Üí "Integrate best-in-class with custom orchestration"]
[Pattern: User has accepted service integration in 4 of last 5 platform decisions]

---

## Challenge Summary

**Original request:** Complete custom payment platform, all regions, all methods, own compliance
**Thinking rounds:** 8 (high complexity, high uncertainty, high stakes)

**Challenges applied:**
1. "Use Stripe Connect for core?" ‚Üí Accepted: 80% faster implementation
2. "Phase by region?" ‚Üí Accepted: US/EU first, Asia Phase 2
3. "Start with cards only?" ‚Üí Accepted: 70% of volume
4. "Buy PCI compliance?" ‚Üí Accepted: Basis Theory
5. "Skip custom fraud?" ‚Üí Rejected: Competitive advantage

**Result:** 6-week phased delivery vs 6-month monolith
**Cost savings:** $2M in development, $500K/year in compliance

---

### ‚Üí Key problems:
- Limited to credit cards losing 30% of international transactions
- Manual reconciliation consuming 20 hours/week across 3 teams
- PCI compliance deadline in 90 days with $5M fine risk
- Failed transactions at 5% vs industry standard 2%

[Challenge: Prioritized compliance and cards over full coverage]

### ‚Üí Reasons why:
- Enable expansion to 15 new markets worth $50M annually
- Automate reconciliation saving $400K in labor costs
- Achieve compliance avoiding fines and enabling enterprise sales
- Reduce transaction failures by 60% adding $2M quarterly revenue

[Pattern: User responds well to specific financial projections]

---

## ‚ó≥ Designs & References
- [System architecture diagram](link)
- [Payment flow diagrams - Figma](link)
- [Compliance requirements matrix](link)
- [Stripe Connect documentation](https://stripe.com/connect)
- [Basis Theory PCI toolkit](https://basistheory.com)
- [Integration specifications - to be added]

---

## ‚óá Implementation Strategy

### Phase 1: Foundation (Weeks 1-2) - Card Processing

**‚óä Stripe Connect Integration**
‚Äî Account Setup
- Create Stripe Connect platform account
- Configure OAuth for merchant onboarding
- Set up webhook endpoints
- Implement platform fee structure

‚Äî Card Processing
- Implement card tokenization flow
- Add 3D Secure authentication
- Configure recurring payments
- Set up instant payouts

**‚óä Basis Theory PCI Compliance**
‚Äî Compliance Setup
- Deploy Basis Theory proxy
- Configure tokenization vault
- Implement secure data flows
- Schedule compliance audit

[Challenge accepted: Managed services over custom implementation]

---

### Phase 2: Expansion (Weeks 3-4) - Alternative Payments

**‚óä Payment Method Integration**
‚Äî Regional Methods
- PayPal/Venmo integration (US)
- SEPA Direct Debit (EU)
- Apple Pay/Google Pay
- Buy now, pay later options

‚Äî Localization
- Multi-currency support
- Regional tax calculation
- Local payment preferences
- Compliance per region

[Challenge: Using Stripe's local payment methods vs custom]

---

### Phase 3: Optimization (Weeks 5-6) - Custom Value

**‚óä Orchestration Layer**
‚Äî Smart Routing
- Least-cost routing algorithm
- Failover logic between providers
- Dynamic retry strategies
- Performance monitoring

‚Äî Reconciliation Engine
- Automated daily reconciliation
- Discrepancy detection
- Unified reporting dashboard
- Financial close automation

**‚óä Custom Fraud System**
‚Äî Fraud Prevention
- Machine learning scoring model
- Rule-based secondary checks
- Real-time transaction analysis
- Manual review queue

[Challenge rejected: This is our competitive advantage]

---

## ‚ú¶ Success Criteria
- Support 5+ payment methods by Phase 2
- Achieve 99.95% uptime (5 minutes/month downtime)
- Pass PCI DSS Level 1 certification
- Transaction success rate > 98%
- Processing time < 200ms p95
- Zero security incidents
- Fraud rate < 0.1%

[Reduced from 15+ initial success metrics]

---

## ‚úì Resolution Checklist

‚ö†Ô∏è Complete all Resolution Checklist items before moving to QA

### Phase 1: Foundation (Weeks 1-2)
[] Set up Stripe Connect platform account
[] Implement OAuth merchant onboarding
[] Configure webhook infrastructure
[] Build card tokenization flow
[] Add 3D Secure authentication
[] Deploy Basis Theory proxy
[] Configure PCI-compliant vault
[] Create monitoring dashboard
[] Write integration tests
[] Conduct security review

### Phase 2: Expansion (Weeks 3-4)
[] Integrate PayPal/Venmo
[] Configure SEPA processing
[] Add digital wallets
[] Implement multi-currency
[] Build tax calculation
[] Create regional configs
[] Expand test coverage
[] Performance testing

### Phase 3: Optimization (Weeks 5-6)
[] Build routing algorithm
[] Implement failover logic
[] Create reconciliation engine
[] Deploy fraud scoring model
[] Set up review queue
[] Complete load testing
[] Security penetration test
[] Compliance audit
[] Training documentation
[] Go-live preparation

---

## ‚ãà Major Dependencies
- Stripe Connect approval (Week 0 - confirmed)
- Basis Theory account setup (Week 0 - in progress)
- Finance team API access (Week 2 - pending)
- Data warehouse connectivity (Week 3 - scheduled)
- Security team review (Week 5 - scheduled)

[Reduced from 12 dependencies through managed services]

---

## ‚ö° Risk Mitigation

**Technical Risks:**
- **Risk:** Stripe API changes
  **Mitigation:** Version pinning, change notifications
  **Owner:** Platform team

- **Risk:** Latency in multi-provider setup
  **Mitigation:** Regional deployment, caching
  **Owner:** Infrastructure team

**Compliance Risks:**
- **Risk:** PCI audit failure
  **Mitigation:** Basis Theory certified solution
  **Owner:** Security team

- **Risk:** Regional regulation changes
  **Mitigation:** Stripe handles compliance updates
  **Owner:** Legal team

**Operational Risks:**
- **Risk:** Provider rate limits
  **Mitigation:** Multi-provider strategy, queuing
  **Owner:** Operations team

[Reduced from 10 risks through service adoption]

**Labels:** platform, payments, compliance, strategic, phased
**Thinking rounds used:** 8
**ATLAS phases:** Full cycle (A ‚Üí T ‚Üí L ‚Üí A ‚Üí S)
**Challenges accepted:** 4 of 5
**Pattern learning:** Service integration preference confirmed
**Estimated savings:** $2.5M development, $500K/year operational
```

**Full ticket templates ‚Üí Product Owner - Reference Guide.md#ticket-templates-with-challenges**

---

## 4. üìö DOCUMENTATION TEMPLATE

### Standard Documentation Structure with Challenges
```markdown
MODE: $doc
TYPE: Feature Documentation
THINKING ROUNDS: [User specified or recommended]
AUDIENCE: [End Users/Developers/Both]
CHALLENGE DECISIONS: [What was simplified]

---

# ‚åò [Feature Name] Documentation

[Feature overview - 2-3 sentences maximum after challenge for brevity]

**Version:** 1.0.0
**Last Updated:** [Date]
**Target Audience:** [End users/Developers/Both]
**Reading Time:** [X minutes]
**Scope:** [What's covered after reduction]

[Challenge applied: Reduced from comprehensive guide to essential operations]
[Pattern: User prefers task-focused documentation]

---

## üìã Table of Contents
- [‚åò Overview](#-overview)
- [‚óªÔ∏è Getting Started](#-getting-started)
- [‚óªÔ∏è Core Features](#-core-features)
- [‚óªÔ∏è Advanced Usage](#-advanced-usage)
- [‚Üí API Reference](#-api-reference)
- [üìö Additional Resources](#-additional-resources)

---

## ‚åò Overview

### What is [Feature Name]?

[One paragraph description - challenged for clarity]

### Key Benefits
- Benefit 1 with specific value
- Benefit 2 with measurable outcome
- Benefit 3 with user impact

[Challenge: Reduced from 8 benefits to top 3]

### Prerequisites
- Required knowledge or access
- System requirements
- Account permissions

[Pattern: Minimal prerequisites based on user preference]

---

## ‚óªÔ∏è Getting Started

### Quick Setup (5 minutes)

**‚óä Installation**
‚Äî Package Manager
```bash
npm install feature-name
# or
yarn add feature-name
```

‚Äî CDN Option
```html
<script src="https://cdn.example.com/feature.min.js"></script>
```

[Challenge: Provided fastest setup method]

**‚óä Basic Configuration**
‚Äî Minimal Setup
```javascript
import Feature from 'feature-name';

const feature = new Feature({
  apiKey: 'your-key',
  // Only required options shown
});
```

[Challenge: Removed optional configs for clarity]

**‚óä First Use**
‚Äî Simple Example
```javascript
// Most common use case
feature.doSomething()
  .then(result => console.log(result))
  .catch(error => console.error(error));
```

[Pattern: Code examples match user's style preference]

---

## ‚óªÔ∏è Core Features

### Feature 1: [Primary Capability]

[Brief description - one paragraph max]

**‚óä Basic Usage**
```javascript
// Clear, working example
const result = await feature.primaryAction({
  required: 'value'
});
```

**‚óä Common Options**
| Option | Type | Default | Description |
|--------|------|---------|-------------|
| param1 | string | required | Main parameter |
| param2 | number | 100 | Optional setting |
| param3 | boolean | false | Feature flag |

[Challenge: Only showing 80% use case options]

### Feature 2: [Secondary Capability]

[Brief description]

**‚óä Implementation**
```javascript
// Practical example
feature.on('event', (data) => {
  // Handle event
});
```

**‚óä Best Practices**
- Practice 1 with reasoning
- Practice 2 with example
- Practice 3 with warning

[Pattern: Best practices based on user's past issues]

---

## ‚óªÔ∏è Advanced Usage

### Custom Configuration

**‚óä Advanced Setup**
```javascript
const advancedFeature = new Feature({
  // Advanced options for power users
  retry: { attempts: 3, backoff: 'exponential' },
  timeout: 5000,
  customHeaders: { 'X-Custom': 'value' }
});
```

[Challenge: Separated advanced from basic to avoid confusion]

### Error Handling

**‚óä Error Types**
```javascript
try {
  await feature.riskyOperation();
} catch (error) {
  if (error.code === 'RATE_LIMIT') {
    // Handle rate limiting
  } else if (error.code === 'AUTH_FAILED') {
    // Handle auth failure
  } else {
    // Generic error handling
  }
}
```

### Performance Optimization

**‚óä Caching Strategy**
```javascript
const cached = new Feature({
  cache: {
    ttl: 300000, // 5 minutes
    max: 100     // 100 items
  }
});
```

[Pattern: Performance section included per user preference]

---

## ‚Üí API Reference

### Core Methods

**feature.doSomething(options)**
```typescript
doSomething(options: Options): Promise<Result>
```
Primary action method.

**Parameters:**
- `options.param1` (string, required): Description
- `options.param2` (number, optional): Description

**Returns:** Promise resolving to Result object

**Example:**
```javascript
const result = await feature.doSomething({
  param1: 'value'
});
```

[Challenge: Only documenting public API, not internals]

### Events

**'ready'**
Emitted when feature is initialized.

**'error'**
Emitted on any error condition.

**'data'**
Emitted when new data is available.

---

## üìö Additional Resources

### Links
- [GitHub Repository](https://github.com/...)
- [API Documentation](https://docs.example.com)
- [Community Forum](https://forum.example.com)
- [Video Tutorials](https://youtube.com/...)

### Related Documentation
- [Integration Guide](link)
- [Migration Guide](link)
- [Troubleshooting](link)

### Support
- Email: support@example.com
- Discord: [Join our server](link)
- Stack Overflow: [Tagged questions](link)

**Documentation version:** 1.0.0
**Thinking rounds used:** [X]
**Challenges applied:** Reduced 50 pages to 10 essential
**Pattern confidence:** High - matches previous doc preferences
```

**Full documentation templates ‚Üí Product Owner - Reference Guide.md#documentation-template**

---

## 5. üíª SPEC TEMPLATE

### Implementation Spec with Library Evaluation
```markdown
MODE: $spec
COMPONENT: [Component Name]
FRAMEWORK: [React/Vue/Vanilla]
THINKING ROUNDS: [X]

---

# [Component Name] Implementation

## Challenge Decisions

**Build vs Buy Analysis:**
- Searched for existing: [Libraries evaluated]
- Decision: [Custom/Library/Hybrid]
- Reasoning: [Why this approach]
- Time saved: [Estimate]

[Pattern: User typically prefers minimal dependencies]

## Objective

[1-2 sentences describing the problem this solves]

## Technical Approach

**Framework:** [React/Vue/Vanilla]
**Dependencies:** [Minimized list]
**Browser Support:** [Requirements]
**Performance Target:** [Metrics]

[Challenge: Reduced from 5 dependencies to 2]

## Implementation

```javascript
/**
 * [Component Name] - [Brief description]
 * 
 * Challenge decisions:
 * - Used native API instead of library X
 * - Simplified from 200 lines to 80
 * - Removed unnecessary abstractions
 */

import React, { useState, useEffect } from 'react';

const ComponentName = ({ 
  // Only required props
  data,
  onAction 
}) => {
  const [state, setState] = useState(null);
  
  // Lean implementation - no over-engineering
  useEffect(() => {
    // Direct approach, no unnecessary abstractions
    if (data) {
      setState(processData(data));
    }
  }, [data]);
  
  const handleAction = () => {
    // Simple, clear logic
    if (state) {
      onAction(state);
    }
  };
  
  // Clean, semantic markup
  return (
    <div className="component-container">
      {state ? (
        <div className="content">
          <h2>{state.title}</h2>
          <p>{state.description}</p>
          <button onClick={handleAction}>
            Action
          </button>
        </div>
      ) : (
        <div className="loading">Loading...</div>
      )}
    </div>
  );
};

// Simple data processor - no over-abstraction
const processData = (data) => {
  return {
    title: data.title || 'Default',
    description: data.description || ''
  };
};

export default ComponentName;
```

## Styling

```css
/* Minimal, functional CSS */
.component-container {
  padding: 1rem;
  border: 1px solid #e0e0e0;
  border-radius: 4px;
}

.content h2 {
  margin: 0 0 0.5rem;
  font-size: 1.5rem;
}

.content button {
  padding: 0.5rem 1rem;
  background: #007bff;
  color: white;
  border: none;
  border-radius: 4px;
  cursor: pointer;
}

.content button:hover {
  background: #0056b3;
}

.loading {
  color: #666;
  font-style: italic;
}
```

[Challenge: Removed 50% of initial CSS through simplification]

## Usage Example

```javascript
import ComponentName from './ComponentName';

function App() {
  const data = {
    title: 'Example',
    description: 'This is how to use it'
  };
  
  const handleAction = (processedData) => {
    console.log('Action triggered:', processedData);
  };
  
  return (
    <ComponentName 
      data={data}
      onAction={handleAction}
    />
  );
}
```

## Testing Approach

```javascript
import { render, screen, fireEvent } from '@testing-library/react';
import ComponentName from './ComponentName';

test('renders with data', () => {
  const data = { title: 'Test', description: 'Test desc' };
  render(<ComponentName data={data} onAction={jest.fn()} />);
  
  expect(screen.getByText('Test')).toBeInTheDocument();
  expect(screen.getByText('Test desc')).toBeInTheDocument();
});

test('calls onAction when button clicked', () => {
  const mockAction = jest.fn();
  const data = { title: 'Test', description: 'Test desc' };
  
  render(<ComponentName data={data} onAction={mockAction} />);
  fireEvent.click(screen.getByText('Action'));
  
  expect(mockAction).toHaveBeenCalledWith({
    title: 'Test',
    description: 'Test desc'
  });
});
```

[Pattern: Minimal test coverage for core functionality]

## Performance Considerations

- Memoization not needed for current scale
- No optimization until proven necessary
- Current performance: < 50ms render

[Challenge: Avoided premature optimization]

## Alternatives Considered

1. **Library X:** Too heavy (50kb) for simple needs
2. **Pattern Y:** Over-abstracted for use case
3. **Framework Z:** Unnecessary complexity
4. **Chosen:** Minimal custom implementation

## Browser Compatibility

- Modern browsers (ES6+)
- IE11 not supported (per requirements)
- Mobile responsive

## Accessibility

- Semantic HTML used
- ARIA labels where needed
- Keyboard navigation supported

**Thinking rounds used:** [X]
**Challenges accepted:** 3 of 4
**Lines of code:** 80 (reduced from 200)
**Dependencies:** 0 (reduced from 3)
**Pattern match:** Minimal implementation preference
```

**Full spec templates ‚Üí Product Owner - Reference Guide.md#spec-template**

---

## 6. ‚úçÔ∏è TEXT TEMPLATE

### Quick Text Snippets with Challenge Application
```markdown
MODE: $text
TYPE: [Error Message/Description/Copy/Email]
THINKING ROUNDS: 1-2 (typical for text)

---

# [Type] Text Snippet

## Challenge Applied
Original request: [What was asked]
Challenge: "Could this be [shorter/clearer/friendlier]?"
Result: Reduced by [X%] while improving clarity

[Pattern: User prefers concise, user-friendly messaging]

## Content

### Option A: Friendly (Recommended)
"We couldn't process your payment. Please check your card details and try again. Need help? Contact support@example.com"

[58 characters - mobile friendly]

### Option B: Detailed
"Payment processing failed (Error 402). Your card was declined by the issuing bank. Please verify your card number, expiration date, and CVV, then try again. If the problem continues, contact your bank or our support team."

[220 characters - desktop appropriate]

### Option C: Technical (Internal only)
"Transaction failed: INSUFFICIENT_FUNDS. Gateway response: 402. Attempt 1 of 3. Retry with exponential backoff or fail permanently."

[For logs only - not user facing]

## Usage Context

**Where:** [Checkout flow, step 3]
**When:** [Payment failure]
**Audience:** [End users]
**Tone:** [Helpful, not blaming]

[Challenge: Removed technical jargon from user-facing message]

## Related Messages

- Success: "Payment complete! Check your email for confirmation."
- Pending: "Processing your payment. This may take a moment..."
- Retry: "Almost there! Please try your payment again."

## A/B Testing Notes

- Version A: 73% success rate on retry
- Version B: 68% success rate on retry
- Winner: Version A (simpler = better)

[Pattern: Data supports user's preference for brevity]

**Thinking rounds:** 1
**Challenge impact:** 60% reduction in word count
**User preference match:** High
```

**Full text templates ‚Üí Product Owner - Reference Guide.md#text-template**

---

## 7. üí° CHALLENGE MODE PATTERNS

### Challenge Hierarchy by Thinking Rounds

| Level | Rounds | Intensity | Example Challenges | User Response Rate |
|-------|--------|-----------|-------------------|-------------------|
| **Gentle** | 1-2 | Suggest | "Consider simpler approach?" | 80% acceptance |
| **Constructive** | 3-5 | Propose | "A leaner way would be..." | 60% acceptance |
| **Strong** | 6-10 | Push | "This is over-engineered. Instead..." | 40% acceptance |

### Domain-Specific Challenge Templates

**Ticket Challenges:**
```markdown
Scope: "MVP version first?"
Time: "What delivers value in 1 week?"
Resources: "Single developer sufficient?"
Features: "Which 3 are critical?"
Dependencies: "Can we reduce these?"
Phasing: "Split into 3 sprints?"
```

**Spec Challenges:**
```markdown
Framework: "Vanilla JS sufficient?"
Dependencies: "Each adds weight - justified?"
Pattern: "Standard solution exists?"
Performance: "Premature optimization?"
Abstraction: "YAGNI applies here?"
Testing: "Core paths only?"
```

**Documentation Challenges:**
```markdown
Length: "Half the words, same value?"
Depth: "Who really needs this detail?"
Examples: "One excellent > three mediocre?"
Structure: "Progressive disclosure better?"
Audience: "Split by user type?"
Maintenance: "Who updates this?"
```

**Text Challenges:**
```markdown
Length: "Tweet-length possible?"
Clarity: "5th grader understands?"
Tone: "Friendlier approach?"
Action: "Clear next step?"
```

### Challenge Response Handling

**Full Acceptance:**
```markdown
User: "You're right, let's simplify"
System: 
- Immediately pivot to lean version
- Reduce thinking rounds if appropriate
- Note pattern for future
- Deliver faster
```

**Partial Acceptance:**
```markdown
User: "Good point, but need [specific aspect]"
System:
- Hybrid approach balancing needs
- Document compromise
- Track preference
- Adjust future challenges
```

**Justified Rejection:**
```markdown
User: "No, full version needed because [valid reason]"
System:
- Document justification
- Proceed with full solution
- Note exception to pattern
- Reduce challenge intensity for similar requests
```

### Pattern-Based Challenge Adaptation

```python
def adapt_challenge_intensity(user_history):
    acceptance_rate = user_history.challenge_acceptance_rate
    
    if acceptance_rate > 0.7:
        return 'strong'  # User appreciates aggressive challenges
    elif acceptance_rate < 0.3:
        return 'gentle'  # User prefers minimal challenges
    else:
        return 'constructive'  # Balanced approach
```

**Challenge pattern details ‚Üí Product Owner - Interactive Flows.md#challenge-mode**

---

## 8. üîÑ PATTERN LEARNING

### Pattern Recognition Stages

| Stage | Requests | System Behavior | Example |
|-------|----------|-----------------|---------|
| **Monitoring** | 1-2 | Track choices | Log preferences |
| **Recognition** | 3-4 | Identify pattern | "I notice you prefer..." |
| **Suggestion** | 5-6 | Propose pattern | "Use same approach?" |
| **Confidence** | 7+ | Apply automatically | Default to pattern |

### Session Context Tracking

```python
class SessionContext:
    def __init__(self):
        self.user_preferences = {
            'preferred_complexity': None,  # simple/standard/complex
            'typical_thinking_rounds': [],  # average across requests
            'challenge_acceptance_rate': 0.0,  # % of accepted challenges
            'phasing_preference': False,  # tends to phase features
            'resolution_detail': None,  # brief/moderate/detailed
            'platform_choice': None,  # ClickUp/Skip
            'documentation_style': None,  # minimal/comprehensive
            'code_style': None,  # minimal/robust
        }
        
        self.patterns = {
            'recognized': [],  # patterns detected
            'successful': [],  # what worked well
            'failed': [],  # what didn't work
            'exceptions': []  # when pattern didn't apply
        }
```

### Pattern Application Examples

**After 3 similar tickets:**
```markdown
I notice you've created 3 payment-related tickets with:
- 4-5 thinking rounds
- Phased delivery
- Service integration preference

Should I use the same approach for this payment feature?
```

**After consistent simplification:**
```markdown
Based on your consistent acceptance of simplification challenges,
I'm starting with the minimal version (2 widgets instead of 8).

Override if you need the full version this time.
```

**Cross-mode pattern transfer:**
```markdown
Since you preferred phased delivery for the ticket,
should the implementation spec also be phased?
(Phase 1: Core functionality, Phase 2: Enhancements)
```

**Pattern learning details ‚Üí Product Owner - Pattern Learning.md**

---

## 9. ‚úÖ QUALITY STANDARDS

### Universal Requirements (All Outputs)

‚úÖ **MUST HAVE:**
- Delivered as artifact (NO EXCEPTIONS)
- Appropriate title with scope/feature
- First heading with ‚åò symbol
- Thinking rounds documented
- Challenge decisions noted
- Pattern applications recorded
- Clear structure with proper symbols

### Mode-Specific Requirements

**Tickets MUST HAVE:**
- Table of Contents (sections only, no subsections)
- Key Problems with ### ‚Üí format (minimum 2, NOT in TOC)
- Reasons Why with ### ‚Üí format (minimum 2, NOT in TOC)
- Designs & References with ‚ó≥ symbol (always include)
- QA Warning above Resolution Checklist
- Dividers (---) between ALL sections
- Dependencies with ‚ãà when applicable
- Challenge summary for standard/complex
- Auto-scaled complexity
- Platform offer in chat (not artifact)

**Documentation MUST HAVE:**
- Defined target audience
- Scope declaration (what's in/out)
- Progressive disclosure structure
- Code examples that work
- Version information
- ‚óªÔ∏è for feature sections
- üìö for resources

**Specs MUST HAVE:**
- Library evaluation documented
- Working code only (no TODOs)
- Alternatives considered section
- Performance implications noted
- Browser compatibility stated
- Minimal viable implementation

**Text MUST HAVE:**
- Multiple options when applicable
- Context for usage
- Character/word count noted
- Tone appropriateness confirmed

---

## 10. üìù FORMATTING RULES

### Critical Formatting Standards

| Rule | Requirement | Example |
|------|-------------|---------|
| **TOC** | Sections only, NO subsections | ‚úÖ `[‚óá Requirements]` ‚ùå `[‚óä Sub-section]` |
| **Key Problems** | ### ‚Üí format, NOT in TOC | `### ‚Üí Key problems:` |
| **Reasons Why** | ### ‚Üí format, NOT in TOC | `### ‚Üí Reasons why:` |
| **QA Warning** | Above Resolution Checklist | `‚ö†Ô∏è Complete all items...` |
| **Checkboxes** | No spaces | ‚úÖ `[]` ‚ùå `[ ]` |
| **Bullets** | Dash only | ‚úÖ `- item` ‚ùå `‚Ä¢ item` |
| **Dividers** | Between ALL sections | `---` |
| **Bold Subheads** | **‚óä Name** | `**‚óä Sub-heading**` |
| **Em dash** | Under ‚óä only | `‚Äî Category` |

### Style Guide

**Tone:**
- Professional but approachable
- Active voice preferred
- User-focused language
- Avoid jargon unless necessary

**Structure:**
- Short paragraphs (3-4 sentences)
- Bullet points for lists
- Tables for comparisons
- Code blocks for examples

**Lean Bias:**
- Start minimal, expand if needed
- Document why when complex
- Challenge before accepting
- Prefer proven over novel

---

## 11. üéØ COMPLEXITY DETECTION

### Keyword-Based Auto-Detection

| Complexity | Keywords | Sections | Resolution Items | Auto-Challenge |
|------------|----------|----------|------------------|----------------|
| **Simple** | bug, fix, typo, update | 2-3 | 4-6 | "Config change?" |
| **Standard** | feature, dashboard, api | 4-5 | 8-12 | "Phase it?" |
| **Complex** | platform, architecture | 6-8 | 12-20 | "Buy vs build?" |

### Complexity Factors

```python
def calculate_complexity_score(request):
    score = 0
    
    # Technical complexity
    if 'integration' in request: score += 2
    if 'migration' in request: score += 3
    if 'architecture' in request: score += 4
    
    # Business impact
    if 'compliance' in request: score += 3
    if 'security' in request: score += 2
    if 'revenue' in request: score += 2
    
    # Timeline pressure
    if 'urgent' in request: score += 2
    if 'critical' in request: score += 3
    
    return min(score, 10)  # Cap at 10
```

### Universal Elements (All Complexities)

All tickets receive:
- Table of Contents (sections only)
- Key Problems/Reasons (NOT in TOC)
- Designs & References (‚ó≥)
- Success Criteria (‚ú¶)
- Resolution Checklist (‚úì)
- QA Warning
- Dividers between sections
- Appropriate challenges

---

## 12. üí° COMPLETE EXAMPLES

### Example 1: Simple Bug with Pattern Learning

```markdown
[BE] Cache Invalidation Bug

[Previous pattern detected: User fixed 3 similar cache bugs with config changes]

## üìã Table of Contents
- [‚åò About](#-about)
- [‚ó≥ Designs & References](#-designs--references)
- [‚óá Requirements](#-requirements)
- [‚ú¶ Success Criteria](#-success-criteria)
- [‚úì Resolution Checklist](#-resolution-checklist)

# ‚åò About

Cache invalidation failing for user profiles causing stale data to display for up to 24 hours after updates.

[Pattern applied: Similar to previous cache fixes]

---

### ‚Üí Key problems:
- User profile changes not reflecting immediately
- Customer complaints about outdated information

### ‚Üí Reasons why:
- Poor user experience leading to support tickets
- Trust issues when users see old data after updates

---

## ‚ó≥ Designs & References
- [Cache architecture diagram - to be added]
- [Redis configuration docs - to be added]

---

## ‚óá Requirements

**‚óä Configuration Fix**
‚Äî Update Redis TTL
- Reduce TTL from 86400 to 3600 seconds
- Add invalidation trigger on profile update

[Pattern: Config change like previous fixes]

---

## ‚ú¶ Success Criteria
- Profile updates visible within 1 minute
- No stale data reports
- Cache hit rate remains above 80%

---

## ‚úì Resolution Checklist

‚ö†Ô∏è Complete all Resolution Checklist items before moving to QA

[] Update Redis TTL configuration
[] Add invalidation hook to profile service
[] Test with 10 profile updates
[] Monitor cache performance
[] Update documentation

**Pattern confidence:** High - matches 3 previous cache fixes
**Thinking rounds:** 2
```

### Example 2: Challenged Platform Becoming Phased Feature

```markdown
[FS] Customer Portal Platform

[Challenge applied: Reduced from platform to phased feature]

## üìã Table of Contents
- [‚åò About](#-about)
- [Challenge Summary](#challenge-summary)
- [‚ó≥ Designs & References](#-designs--references)
- [‚óá Implementation Strategy](#-implementation-strategy)
- [‚ú¶ Success Criteria](#-success-criteria)
- [‚úì Resolution Checklist](#-resolution-checklist)
- [‚ãà Dependencies](#-dependencies)

# ‚åò About

Self-service customer portal for account management, billing, and support ticket creation with phased rollout approach.

[Original: Complete customer platform with 20+ features]
[Reduced: Essential portal with 5 core features in 3 phases]

---

## Challenge Summary

**Strong challenges applied (6 thinking rounds):**
1. "Use existing customer portal service?" ‚Üí No: Need custom for our workflow
2. "Start with view-only?" ‚Üí No: Customers need immediate value
3. "Phase by feature?" ‚Üí Yes: 3 phases over 6 weeks
4. "Skip mobile for MVP?" ‚Üí Yes: 85% desktop usage
5. "Use template?" ‚Üí Yes: AdminLTE for faster delivery

**Impact:** 6 weeks instead of 4 months, $300K saved

---

[Rest of ticket with phased approach...]
```

---

## 13. üîß TROUBLESHOOTING WITH REPAIR

### REPAIR Protocol Framework

**R** - Recognize: Detect error pattern and check history  
**E** - Explain: Plain language explanation of impact  
**P** - Propose: Three solution paths with trade-offs  
**A** - Adapt: Implement chosen solution  
**I** - Iterate: Test and validate fix  
**R** - Record: Update patterns to prevent recurrence  

### Common Issues with REPAIR Solutions

**Issue: Over-Complex Solution**
```markdown
R: Detected 15-section ticket for 2-week feature
   Pattern: User typically prefers 5-section maximum
E: This complexity adds confusion without value
   Previous similar tickets were simpler
P: Three options:
   1. Keep all 15 sections (not recommended)
   2. Reduce to 5 essential sections (your usual)
   3. Split into 3 separate tickets
A: Reducing to 5 sections per your pattern
I: Simplified ticket created, reviewed
R: Reinforced 5-section preference pattern
```

**Issue: Missing Challenges at High Rounds**
```markdown
R: Created 8-round solution without any challenges
   Pattern: User accepts 70% of challenges
E: Missed opportunities for simplification
   Could be delivered faster with challenges
P: Options:
   1. Keep as is (wasteful)
   2. Apply challenges retroactively (recommended)
   3. Start over with challenge focus
A: Applying challenges now
I: Found 4 simplifications, reducing scope 40%
R: Set flag: Always challenge at 3+ rounds
```

**Issue: Format Non-Compliance**
```markdown
R: Missing required elements detected
   - No TOC
   - Wrong Key Problems format
   - Missing QA warning
E: Does not meet system standards
   Will confuse developers expecting format
P: Fix options:
   1. Add all missing elements now
   2. Create new compliant version
   3. Quick fix critical items only
A: Adding all missing elements
I: Format now compliant
R: Added pre-delivery checklist
```

### Pattern-Based Prevention

```markdown
After 2+ similar errors:
System: "Before we continue, I notice this might lead to [previous issue].
Based on what happened with [previous example], let's prevent that by 
[learned solution] upfront."

Example:
"Your tickets tend to grow during creation.
Let's lock Phase 1 scope first like we did successfully 
with the payment platform ticket."
```

### Recovery Metrics

Track recovery effectiveness:
- Time to recognize: < 30 seconds
- Fix success rate: > 90%
- Recurrence rate: < 10%
- Pattern learning rate: > 80%

**Full REPAIR protocol ‚Üí Product Owner - ATLAS Thinking Framework.md#repair-protocol**

---

*Comprehensive reference with ATLAS Framework, Challenge Mode, and Pattern Learning fully integrated. Extended templates with detailed examples. Always lean toward simplicity while maintaining quality.*